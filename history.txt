# first test
python3 train_dsb.py --experiment DSB00001 --batch-size 10 --arch UNet --deep_supervision false --optimizer SGD
python3 train_dsb.py --experiment DSB00002 --batch-size 10 --arch NestedUNet --deep_supervision false --optimizer SGD
python3 train_dsb.py --experiment DSB00003 --batch-size 10 --arch NestedUNet --deep_supervision true --optimizer SGD

#test  for adam
python3 train_dsb.py --experiment DSB00004 --batch-size 10 --arch UNet --deep_supervision false --optimizer Adam  --learning-rate 1e-3
python3 train_dsb.py --experiment DSB00005 --batch-size 10 --arch NestedUNet --deep_supervision false --optimizer Adam  --learning-rate 1e-3
python3 train_dsb.py --experiment DSB00006 --batch-size 10 --arch NestedUNet --deep_supervision true --optimizer Adam  --learning-rate 1e-3

python3 train_dsb.py --experiment DSB00007 --batch-size 10 --arch UNet --deep_supervision false --optimizer Adam  --learning-rate 1e-1
python3 train_dsb.py --experiment DSB00008 --batch-size 10 --arch NestedUNet --deep_supervision false --optimizer Adam  --learning-rate 1e-1
python3 train_dsb.py --experiment DSB00009 --batch-size 10 --arch NestedUNet --deep_supervision true --optimizer Adam  --learning-rate 1e-1

python3 train_dsb.py --experiment DSB00010 --batch-size 10 --arch UNet --deep_supervision false --optimizer Adam  --learning-rate 1e-2
python3 train_dsb.py --experiment DSB00011 --batch-size 10 --arch NestedUNet --deep_supervision false --optimizer Adam  --learning-rate 1e-2
python3 train_dsb.py --experiment DSB00012 --batch-size 10 --arch NestedUNet --deep_supervision true --optimizer Adam  --learning-rate 1e-2


# first test for deep supervision and  weight loss
#test dataset U373
python3 train_mic.py --experiment MIC00001 --batch-size 1 --arch NestedUNet --deep_supervision false --optimizer SGD --scale -1
python3 train_mic.py --experiment MIC00002 --batch-size 1 --arch NestedUNet --deep_supervision true --optimizer SGD --scale -1
python3 train_mic.py --experiment MIC00003 --batch-size 1 --arch NestedUNet --deep_supervision false --optimizer SGD --scale -1
python3 train_mic.py --experiment MIC00004 --batch-size 1 --arch UNet --deep_supervision false --optimizer SGD --scale -1 --weight_loss false
python3 train_mic.py --experiment MIC00005 --batch-size 1 --arch UNet --deep_supervision false --optimizer SGD --scale -1
python3 train_mic.py --experiment MIC00006 --batch-size 1 --arch NestedUNet --deep_supervision true --optimizer SGD --scale -1 --weight_loss false

#test dataset HeLa
python3 train_mic.py --experiment MIC00007 --batch-size 1 --arch NestedUNet --deep_supervision true --optimizer SGD --scale -1 --data_name Hela
python3 train_mic.py --experiment MIC00008 --batch-size 1 --arch NestedUNet --deep_supervision false --optimizer SGD --scale -1 --data_name Hela
python3 train_mic.py --experiment MIC00009 --batch-size 1 --arch UNet --deep_supervision false --optimizer SGD --scale -1 --weight_loss false --data_name Hela
python3 train_mic.py --experiment MIC00010 --batch-size 1 --arch UNet --deep_supervision false --optimizer SGD --scale -1 --data_name Hela
python3 train_mic.py --experiment MIC00011 --batch-size 1 --arch NestedUNet --deep_supervision true --optimizer SGD --scale -1 --weight_loss false --data_name Hela

#test dataset ISBI
python3 train_mic.py --experiment MIC00012 --batch-size 1 --arch NestedUNet --deep_supervision true --optimizer SGD --scale -1 --data_name ISBI
python3 train_mic.py --experiment MIC00013 --batch-size 1 --arch NestedUNet --deep_supervision false --optimizer SGD --scale -1 --data_name ISBI
python3 train_mic.py --experiment MIC00014 --batch-size 1 --arch UNet --deep_supervision false --optimizer SGD --scale -1 --weight_loss false --data_name ISBI
python3 train_mic.py --experiment MIC00015 --batch-size 1 --arch UNet --deep_supervision false --optimizer SGD --scale -1 --data_name ISBI
python3 train_mic.py --experiment MIC00016 --batch-size 1 --arch NestedUNet --deep_supervision true --optimizer SGD --scale -1 --weight_loss false --data_name ISBI

#test for different implement  weights for loss

#for NestedUNet  without deep_supervision
python3 train_mic.py --experiment MIC00017 --batch-size 1 --arch NestedUNet --deep_supervision false --optimizer SGD --scale -1 --weight_loss false  --loss BCEWithLogitsLoss --data_name Hela --epochs 60
python3 train_mic.py --experiment MIC00018 --batch-size 1 --arch NestedUNet --deep_supervision false --optimizer SGD --scale -1 --weight_loss true  --loss WeightBCELoss --data_name Hela --epochs 60
python3 train_mic.py --experiment MIC00019 --batch-size 1 --arch NestedUNet --deep_supervision false --optimizer SGD --scale -1 --weight_loss true  --loss WeightBCELossNormal --data_name Hela --epochs 60

#for NestedUNet  with deep_supervision
python3 train_mic.py --experiment MIC00020 --batch-size 1 --arch NestedUNet --deep_supervision true --optimizer SGD --scale -1 --weight_loss false  --loss BCEWithLogitsLoss --data_name Hela --epochs 60
python3 train_mic.py --experiment MIC00021 --batch-size 1 --arch NestedUNet --deep_supervision true --optimizer SGD --scale -1 --weight_loss true  --loss WeightBCELoss --data_name Hela --epochs 60
python3 train_mic.py --experiment MIC00022 --batch-size 1 --arch NestedUNet --deep_supervision true --optimizer SGD --scale -1 --weight_loss true  --loss WeightBCELossNormal --data_name Hela --epochs 60

#for UNet  has no deep_supervision implment
python3 train_mic.py --experiment MIC00023 --batch-size 1 --arch NestedUNet --deep_supervision false --optimizer SGD --scale -1 --weight_loss false  --loss BCEWithLogitsLoss --data_name Hela --epochs 60
python3 train_mic.py --experiment MIC00024 --batch-size 1 --arch NestedUNet --deep_supervision false --optimizer SGD --scale -1 --weight_loss true  --loss WeightBCELoss --data_name Hela --epochs 60
python3 train_mic.py --experiment MIC00025 --batch-size 1 --arch NestedUNet --deep_supervision false --optimizer SGD --scale -1 --weight_loss true  --loss WeightBCELossNormal --data_name Hela --epochs 60


#test for AVG
python3 train_mic.py --experiment MIC00026 --batch-size 1 --arch NestedUNet --deep_supervision true --optimizer SGD --scale -1 --weight_loss true  --loss WeightBCELoss --data_name HeLa --epochs 60
python3 train_mic.py --experiment MIC00027 --batch-size 1 --arch NestedUNet --deep_supervision true --optimizer SGD --scale -1 --weight_loss true  --loss WeightBCELoss --data_name HeLa --epochs 60
python3 train_mic.py --experiment MIC00028 --batch-size 1 --arch NestedUNet --deep_supervision true --optimizer SGD --scale -1 --weight_loss true  --loss WeightBCELoss --data_name HeLa --epochs 60
python3 train_mic.py --experiment MIC00029 --batch-size 1 --arch NestedUNet --deep_supervision true --optimizer SGD --scale -1 --weight_loss true  --loss WeightBCELoss --data_name HeLa --epochs 60
python3 train_mic.py --experiment MIC00030 --batch-size 1 --arch NestedUNet --deep_supervision true --optimizer SGD --scale -1 --weight_loss true  --loss WeightBCELoss --data_name HeLa --epochs 60
python3 train_mic.py --experiment MIC00031 --batch-size 1 --arch NestedUNet --deep_supervision true --optimizer SGD --scale -1 --weight_loss true  --loss WeightBCELoss --data_name HeLa --epochs 60
python3 train_mic.py --experiment MIC00032 --batch-size 1 --arch NestedUNet --deep_supervision true --optimizer SGD --scale -1 --weight_loss true  --loss WeightBCELoss --data_name HeLa --epochs 60
python3 train_mic.py --experiment MIC00033 --batch-size 1 --arch NestedUNet --deep_supervision true --optimizer SGD --scale -1 --weight_loss true  --loss WeightBCELoss --data_name HeLa --epochs 60
python3 train_mic.py --experiment MIC00034 --batch-size 1 --arch NestedUNet --deep_supervision true --optimizer SGD --scale -1 --weight_loss true  --loss WeightBCELoss --data_name HeLa --epochs 60
python3 train_mic.py --experiment MIC00035 --batch-size 1 --arch NestedUNet --deep_supervision true --optimizer SGD --scale -1 --weight_loss true  --loss WeightBCELoss --data_name HeLa --epochs 60

#for UNet  has no deep_supervision implment
python3 train_mic.py --experiment MIC00036 --batch-size 1 --arch UNet --deep_supervision false --optimizer SGD --scale -1 --weight_loss false  --loss BCEWithLogitsLoss --data_name HeLa --epochs 60
python3 train_mic.py --experiment MIC00037 --batch-size 1 --arch UNet --deep_supervision false --optimizer SGD --scale -1 --weight_loss true  --loss WeightBCELoss --data_name HeLa --epochs 60
python3 train_mic.py --experiment MIC00038 --batch-size 1 --arch UNet --deep_supervision false --optimizer SGD --scale -1 --weight_loss true  --loss WeightBCELossNormal --data_name HeLa --epochs 60



1. focus on methods with default value
python3 train_dsb.py --experiment BASIC0001 --batch-size 10 --arch NestedUNet --deep_supervision false --optimizer Adam  --learning-rate 3e-4 --epochs 50 --weight_loss false --save_check_point false  --force_save_last true
python3 train_dsb.py --experiment BASIC0002 --batch-size 10 --arch NestedUNet --deep_supervision true --optimizer Adam  --learning-rate 3e-4 --epochs 50 --weight_loss false --save_check_point false --force_save_last true
python3 train_dsb.py --experiment BASIC0003 --batch-size 10 --arch UNet --deep_supervision false --optimizer Adam  --learning-rate 1e-2 --momentum 0.99 --epochs 50 --weight_loss false --save_check_point false --force_save_last true

python3 train_mic.py --experiment BASIC0004 --batch-size 1 --arch NestedUNet --deep_supervision false --optimizer Adam --scale -1 --weight_loss false  --loss BCEWithLogitsLoss --data_name U373 --epochs 50 --learning-rate 3e-4 --save_check_point false --force_save_last true
python3 train_mic.py --experiment BASIC0005 --batch-size 1 --arch NestedUNet --deep_supervision true --optimizer Adam --scale -1 --weight_loss false  --loss BCEWithLogitsLoss --data_name U373 --epochs 50 --learning-rate 3e-4 --save_check_point false --force_save_last true
python3 train_mic.py --experiment BASIC0006 --batch-size 1 --arch UNet --deep_supervision false --optimizer SGD --scale -1 --weight_loss true  --loss WeightBCELoss --data_name U373 --epochs 50 --learning-rate 1e-2  --momentum 0.99 --save_check_point false --force_save_last true

python3 train_mic.py --experiment BASIC0007 --batch-size 1 --arch NestedUNet --deep_supervision false --optimizer Adam --scale -1 --weight_loss false  --loss BCEWithLogitsLoss --data_name HeLa --epochs 50 --learning-rate 3e-4 --save_check_point false --force_save_last true
python3 train_mic.py --experiment BASIC0008 --batch-size 1 --arch NestedUNet --deep_supervision true --optimizer Adam --scale -1 --weight_loss false  --loss BCEWithLogitsLoss --data_name HeLa --epochs 50 --learning-rate 3e-4 --save_check_point false --force_save_last true
python3 train_mic.py --experiment BASIC0009 --batch-size 1 --arch UNet --deep_supervision false --optimizer SGD --scale -1 --weight_loss true  --loss WeightBCELoss --data_name HeLa --epochs 50 --learning-rate 1e-2  --momentum 0.99 --save_check_point false --force_save_last true

python3 train_mic.py --experiment BASIC0010 --batch-size 1 --arch NestedUNet --deep_supervision false --optimizer Adam --scale -1 --weight_loss false  --loss BCEWithLogitsLoss --data_name ISBI --epochs 50 --learning-rate 3e-4 --save_check_point false --force_save_last true
python3 train_mic.py --experiment BASIC0011 --batch-size 1 --arch NestedUNet --deep_supervision true --optimizer Adam --scale -1 --weight_loss false  --loss BCEWithLogitsLoss --data_name ISBI --epochs 50 --learning-rate 3e-4 --save_check_point false --force_save_last true
python3 train_mic.py --experiment BASIC0012 --batch-size 1 --arch UNet --deep_supervision false --optimizer SGD --scale -1 --weight_loss true  --loss WeightBCELoss --data_name ISBI --epochs 50 --learning-rate 1e-2  --momentum 0.99 --save_check_point false  --force_save_last true


===============================================================================================
分割线1
===============================================================================================

# 1. HeLa 数据集
# baselise
python3 train_mic.py --experiment HeLa0001 --batch-size 1 --arch NestedUNet --deep_supervision false --optimizer Adam --scale -1 --weight_loss false  --loss BCEDiceLoss --data_name HeLa --epochs 50 --learning-rate 3e-4 --save_check_point false --force_save_last true
python3 train_mic.py --experiment HeLa0002 --batch-size 1 --arch NestedUNet --deep_supervision true --optimizer Adam --scale -1 --weight_loss false  --loss BCEDiceLoss --data_name HeLa --epochs 50 --learning-rate 3e-4 --save_check_point false --force_save_last true
python3 train_mic.py --experiment HeLa0003 --batch-size 1 --arch UNet --deep_supervision false --optimizer SGD --scale -1 --weight_loss true  --loss WeightBCELoss --data_name HeLa --epochs 50 --learning-rate 1e-2  --momentum 0.99 --save_check_point false  --force_save_last true

# The Control group with weight
python3 train_mic.py --experiment HeLa0004 --batch-size 1 --arch NestedUNet --deep_supervision false --optimizer Adam --scale -1 --weight_loss true  --loss WeightBCEDiceLoss --data_name HeLa --epochs 50 --learning-rate 3e-4 --save_check_point false --force_save_last true
python3 train_mic.py --experiment HeLa0005 --batch-size 1 --arch NestedUNet --deep_supervision false --optimizer Adam --scale -1 --weight_loss true  --loss WeightBCELoss --data_name HeLa --epochs 50 --learning-rate 3e-4 --save_check_point false --force_save_last true

python3 train_mic.py --experiment HeLa0006 --batch-size 1 --arch NestedUNet --deep_supervision true --optimizer Adam --scale -1 --weight_loss true  --loss WeightBCEDiceLoss --data_name HeLa --epochs 50 --learning-rate 3e-4 --save_check_point false --force_save_last true
python3 train_mic.py --experiment HeLa0007 --batch-size 1 --arch NestedUNet --deep_supervision true --optimizer Adam --scale -1 --weight_loss true  --loss WeightBCELoss --data_name HeLa --epochs 50 --learning-rate 3e-4 --save_check_point false --force_save_last true

python3 train_mic.py --experiment HeLa0008 --batch-size 1 --arch UNet --deep_supervision false --optimizer SGD --scale -1 --weight_loss false  --loss BCEWithLogitsLoss --data_name HeLa --epochs 50 --learning-rate 1e-2  --momentum 0.99 --save_check_point false  --force_save_last true
python3 train_mic.py --experiment HeLa0009 --batch-size 1 --arch UNet --deep_supervision false --optimizer SGD --scale -1 --weight_loss true  --loss WeightBCEDiceLoss --data_name HeLa --epochs 50 --learning-rate 1e-2  --momentum 0.99 --save_check_point false  --force_save_last true

#The Control group with optimizer
python3 train_mic.py --experiment HeLa0010 --batch-size 1 --arch UNet --deep_supervision false --optimizer Adam --scale -1 --weight_loss true  --loss WeightBCELoss --data_name HeLa --epochs 50 --learning-rate 3e-4  --momentum 0.9 --save_check_point false  --force_save_last true


# 2. ISBI 数据集
# baselise
python3 train_mic.py --experiment ISBI0001 --batch-size 1 --arch NestedUNet --deep_supervision false --optimizer Adam --scale -1 --weight_loss false  --loss BCEDiceLoss --data_name ISBI --epochs 50 --learning-rate 3e-4 --save_check_point false --force_save_last true
python3 train_mic.py --experiment ISBI0002 --batch-size 1 --arch NestedUNet --deep_supervision true --optimizer Adam --scale -1 --weight_loss false  --loss BCEDiceLoss --data_name ISBI --epochs 50 --learning-rate 3e-4 --save_check_point false --force_save_last true
python3 train_mic.py --experiment ISBI0003 --batch-size 1 --arch UNet --deep_supervision false --optimizer SGD --scale -1 --weight_loss true  --loss WeightBCELoss --data_name ISBI --epochs 50 --learning-rate 1e-2  --momentum 0.99 --save_check_point false  --force_save_last true

# The Control group with weight
python3 train_mic.py --experiment ISBI0004 --batch-size 1 --arch NestedUNet --deep_supervision false --optimizer Adam --scale -1 --weight_loss true  --loss WeightBCEDiceLoss --data_name ISBI --epochs 50 --learning-rate 3e-4 --save_check_point false --force_save_last true
python3 train_mic.py --experiment ISBI0005 --batch-size 1 --arch NestedUNet --deep_supervision false --optimizer Adam --scale -1 --weight_loss true  --loss WeightBCELoss --data_name ISBI --epochs 50 --learning-rate 3e-4 --save_check_point false --force_save_last true

python3 train_mic.py --experiment ISBI0006 --batch-size 1 --arch NestedUNet --deep_supervision true --optimizer Adam --scale -1 --weight_loss true  --loss WeightBCEDiceLoss --data_name ISBI --epochs 50 --learning-rate 3e-4 --save_check_point false --force_save_last true
python3 train_mic.py --experiment ISBI0007 --batch-size 1 --arch NestedUNet --deep_supervision true --optimizer Adam --scale -1 --weight_loss true  --loss WeightBCELoss --data_name ISBI --epochs 50 --learning-rate 3e-4 --save_check_point false --force_save_last true

python3 train_mic.py --experiment ISBI0008 --batch-size 1 --arch UNet --deep_supervision false --optimizer SGD --scale -1 --weight_loss false  --loss BCEWithLogitsLoss --data_name ISBI --epochs 50 --learning-rate 1e-2  --momentum 0.99 --save_check_point false  --force_save_last true
python3 train_mic.py --experiment ISBI0009 --batch-size 1 --arch UNet --deep_supervision false --optimizer SGD --scale -1 --weight_loss true  --loss WeightBCEDiceLoss --data_name ISBI --epochs 50 --learning-rate 1e-2  --momentum 0.99 --save_check_point false  --force_save_last true

#The Control group with optimizer
python3 train_mic.py --experiment ISBI0010 --batch-size 1 --arch UNet --deep_supervision false --optimizer Adam --scale -1 --weight_loss true  --loss WeightBCELoss --data_name ISBI --epochs 50 --learning-rate 3e-4  --momentum 0.9 --save_check_point false  --force_save_last true

# 2. DSB 数据集
# baselise
python3 train_dsb.py --experiment DSB0001 --batch-size 1 --arch NestedUNet --deep_supervision false --optimizer Adam --weight_loss false  --loss BCEDiceLoss  --epochs 50 --learning-rate 3e-4 --save_check_point false --force_save_last true
python3 train_dsb.py --experiment DSB0002 --batch-size 1 --arch NestedUNet --deep_supervision true --optimizer Adam  --weight_loss false  --loss BCEDiceLoss  --epochs 50 --learning-rate 3e-4 --save_check_point false --force_save_last true
python3 train_dsb.py --experiment DSB0003 --batch-size 1 --arch UNet --deep_supervision false --optimizer SGD  --weight_loss true  --loss WeightBCELoss  --epochs 50 --learning-rate 1e-2  --momentum 0.99 --save_check_point false  --force_save_last true

# The Control group with weight
python3 train_dsb.py --experiment DSB0004 --batch-size 1 --arch NestedUNet --deep_supervision false --optimizer Adam  --weight_loss true  --loss WeightBCEDiceLoss  --epochs 50 --learning-rate 3e-4 --save_check_point false --force_save_last true
python3 train_dsb.py --experiment DSB0005 --batch-size 1 --arch NestedUNet --deep_supervision false --optimizer Adam  --weight_loss true  --loss WeightBCELoss  --epochs 50 --learning-rate 3e-4 --save_check_point false --force_save_last true

python3 train_dsb.py --experiment DSB0006 --batch-size 1 --arch NestedUNet --deep_supervision true --optimizer Adam  --weight_loss true  --loss WeightBCEDiceLoss  --epochs 50 --learning-rate 3e-4 --save_check_point false --force_save_last true
python3 train_dsb.py --experiment DSB0007 --batch-size 1 --arch NestedUNet --deep_supervision true --optimizer Adam  --weight_loss true  --loss WeightBCELoss  --epochs 50 --learning-rate 3e-4 --save_check_point false --force_save_last true

python3 train_dsb.py --experiment DSB0008 --batch-size 1 --arch UNet --deep_supervision false --optimizer SGD  --weight_loss false  --loss BCEWithLogitsLoss  --epochs 50 --learning-rate 1e-2  --momentum 0.99 --save_check_point false  --force_save_last true
python3 train_dsb.py --experiment DSB0009 --batch-size 1 --arch UNet --deep_supervision false --optimizer SGD  --weight_loss true  --loss WeightBCEDiceLoss  --epochs 50 --learning-rate 1e-2  --momentum 0.99 --save_check_point false  --force_save_last true

#The Control group with optimizer
python3 train_dsb.py --experiment DSB0010 --batch-size 1 --arch UNet --deep_supervision false --optimizer Adam  --weight_loss true  --loss WeightBCELoss  --epochs 50 --learning-rate 3e-4  --momentum 0.9 --save_check_point false  --force_save_last true

# for PyramidUNet
python3 train_mic.py --experiment P_HeLa0003 --batch-size 1 --arch PyramidUNet --deep_supervision false --optimizer SGD  --weight_loss true  --loss WeightBCELoss --data_name HeLa --epochs 50 --learning-rate 1e-2  --momentum 0.99 --save_check_point false  --force_save_last true
python3 train_mic.py --experiment P_ISBI0003 --batch-size 1 --arch PyramidUNet --deep_supervision false --optimizer SGD  --weight_loss true  --loss WeightBCELoss --data_name ISBI --epochs 50 --learning-rate 1e-2  --momentum 0.99 --save_check_point false  --force_save_last true
python3 train_dsb.py --experiment P_DSB0003 --batch-size 1 --arch PyramidUNet --deep_supervision false --optimizer SGD  --weight_loss true  --loss WeightBCELoss --epochs 50 --learning-rate 1e-2  --momentum 0.99 --save_check_point false  --force_save_last true

# baselise256
python3 train_dsb.py --experiment DSB0001_256 --batch-size 1 --arch NestedUNet --deep_supervision false --optimizer Adam --weight_loss false  --loss BCEDiceLoss  --epochs 50 --learning-rate 3e-4 --save_check_point false --force_save_last true --data_dir dsb2018_256
python3 train_dsb.py --experiment DSB0002_256 --batch-size 1 --arch NestedUNet --deep_supervision true --optimizer Adam  --weight_loss false  --loss BCEDiceLoss  --epochs 50 --learning-rate 3e-4 --save_check_point false --force_save_last true --data_dir dsb2018_256
python3 train_dsb.py --experiment DSB0003_256 --batch-size 1 --arch UNet --deep_supervision false --optimizer SGD  --weight_loss true  --loss WeightBCELoss  --epochs 50 --learning-rate 1e-2  --momentum 0.99 --save_check_point false  --force_save_last true --data_dir dsb2018_256