# first test
python3 train_dsb.py --experiment DSB00001 --batch-size 10 --arch UNet --deep_supervision false --optimizer SGD
python3 train_dsb.py --experiment DSB00002 --batch-size 10 --arch NestedUNet --deep_supervision false --optimizer SGD
python3 train_dsb.py --experiment DSB00003 --batch-size 10 --arch NestedUNet --deep_supervision true --optimizer SGD

#test  for adam
python3 train_dsb.py --experiment DSB00004 --batch-size 10 --arch UNet --deep_supervision false --optimizer Adam  --learning-rate 1e-3
python3 train_dsb.py --experiment DSB00005 --batch-size 10 --arch NestedUNet --deep_supervision false --optimizer Adam  --learning-rate 1e-3
python3 train_dsb.py --experiment DSB00006 --batch-size 10 --arch NestedUNet --deep_supervision true --optimizer Adam  --learning-rate 1e-3

python3 train_dsb.py --experiment DSB00007 --batch-size 10 --arch UNet --deep_supervision false --optimizer Adam  --learning-rate 1e-1
python3 train_dsb.py --experiment DSB00008 --batch-size 10 --arch NestedUNet --deep_supervision false --optimizer Adam  --learning-rate 1e-1
python3 train_dsb.py --experiment DSB00009 --batch-size 10 --arch NestedUNet --deep_supervision true --optimizer Adam  --learning-rate 1e-1

python3 train_dsb.py --experiment DSB00010 --batch-size 10 --arch UNet --deep_supervision false --optimizer Adam  --learning-rate 1e-2
python3 train_dsb.py --experiment DSB00011 --batch-size 10 --arch NestedUNet --deep_supervision false --optimizer Adam  --learning-rate 1e-2
python3 train_dsb.py --experiment DSB00012 --batch-size 10 --arch NestedUNet --deep_supervision true --optimizer Adam  --learning-rate 1e-2


# first test for deep supervision and  weight loss
#test dataset U373
python3 train_mic.py --experiment MIC00001 --batch-size 1 --arch NestedUNet --deep_supervision false --optimizer SGD --scale -1
python3 train_mic.py --experiment MIC00002 --batch-size 1 --arch NestedUNet --deep_supervision true --optimizer SGD --scale -1
python3 train_mic.py --experiment MIC00003 --batch-size 1 --arch NestedUNet --deep_supervision false --optimizer SGD --scale -1
python3 train_mic.py --experiment MIC00004 --batch-size 1 --arch UNet --deep_supervision false --optimizer SGD --scale -1 --weight_loss false
python3 train_mic.py --experiment MIC00005 --batch-size 1 --arch UNet --deep_supervision false --optimizer SGD --scale -1
python3 train_mic.py --experiment MIC00006 --batch-size 1 --arch NestedUNet --deep_supervision true --optimizer SGD --scale -1 --weight_loss false

#test dataset HeLa
python3 train_mic.py --experiment MIC00007 --batch-size 1 --arch NestedUNet --deep_supervision true --optimizer SGD --scale -1 --data_name Hela
python3 train_mic.py --experiment MIC00008 --batch-size 1 --arch NestedUNet --deep_supervision false --optimizer SGD --scale -1 --data_name Hela
python3 train_mic.py --experiment MIC00009 --batch-size 1 --arch UNet --deep_supervision false --optimizer SGD --scale -1 --weight_loss false --data_name Hela
python3 train_mic.py --experiment MIC00010 --batch-size 1 --arch UNet --deep_supervision false --optimizer SGD --scale -1 --data_name Hela
python3 train_mic.py --experiment MIC00011 --batch-size 1 --arch NestedUNet --deep_supervision true --optimizer SGD --scale -1 --weight_loss false --data_name Hela

#test dataset ISBI
python3 train_mic.py --experiment MIC00012 --batch-size 1 --arch NestedUNet --deep_supervision true --optimizer SGD --scale -1 --data_name ISBI
python3 train_mic.py --experiment MIC00013 --batch-size 1 --arch NestedUNet --deep_supervision false --optimizer SGD --scale -1 --data_name ISBI
python3 train_mic.py --experiment MIC00014 --batch-size 1 --arch UNet --deep_supervision false --optimizer SGD --scale -1 --weight_loss false --data_name ISBI
python3 train_mic.py --experiment MIC00015 --batch-size 1 --arch UNet --deep_supervision false --optimizer SGD --scale -1 --data_name ISBI
python3 train_mic.py --experiment MIC00016 --batch-size 1 --arch NestedUNet --deep_supervision true --optimizer SGD --scale -1 --weight_loss false --data_name ISBI

#test for different implement  weights for loss

#for NestedUNet  without deep_supervision
python3 train_mic.py --experiment MIC00017 --batch-size 1 --arch NestedUNet --deep_supervision false --optimizer SGD --scale -1 --weight_loss false  --loss BCEWithLogitsLoss --data_name Hela --epochs 60
python3 train_mic.py --experiment MIC00018 --batch-size 1 --arch NestedUNet --deep_supervision false --optimizer SGD --scale -1 --weight_loss true  --loss WeightBCELoss --data_name Hela --epochs 60
python3 train_mic.py --experiment MIC00019 --batch-size 1 --arch NestedUNet --deep_supervision false --optimizer SGD --scale -1 --weight_loss true  --loss WeightBCELossNormal --data_name Hela --epochs 60

#for NestedUNet  with deep_supervision
python3 train_mic.py --experiment MIC00020 --batch-size 1 --arch NestedUNet --deep_supervision true --optimizer SGD --scale -1 --weight_loss false  --loss BCEWithLogitsLoss --data_name Hela --epochs 60
python3 train_mic.py --experiment MIC00021 --batch-size 1 --arch NestedUNet --deep_supervision true --optimizer SGD --scale -1 --weight_loss true  --loss WeightBCELoss --data_name Hela --epochs 60
python3 train_mic.py --experiment MIC00022 --batch-size 1 --arch NestedUNet --deep_supervision true --optimizer SGD --scale -1 --weight_loss true  --loss WeightBCELossNormal --data_name Hela --epochs 60

#for UNet  has no deep_supervision implment
python3 train_mic.py --experiment MIC00023 --batch-size 1 --arch NestedUNet --deep_supervision false --optimizer SGD --scale -1 --weight_loss false  --loss BCEWithLogitsLoss --data_name Hela --epochs 60
python3 train_mic.py --experiment MIC00024 --batch-size 1 --arch NestedUNet --deep_supervision false --optimizer SGD --scale -1 --weight_loss true  --loss WeightBCELoss --data_name Hela --epochs 60
python3 train_mic.py --experiment MIC00025 --batch-size 1 --arch NestedUNet --deep_supervision false --optimizer SGD --scale -1 --weight_loss true  --loss WeightBCELossNormal --data_name Hela --epochs 60


#test for AVG
python3 train_mic.py --experiment MIC00026 --batch-size 1 --arch NestedUNet --deep_supervision true --optimizer SGD --scale -1 --weight_loss true  --loss WeightBCELoss --data_name HeLa --epochs 60
python3 train_mic.py --experiment MIC00027 --batch-size 1 --arch NestedUNet --deep_supervision true --optimizer SGD --scale -1 --weight_loss true  --loss WeightBCELoss --data_name HeLa --epochs 60
python3 train_mic.py --experiment MIC00028 --batch-size 1 --arch NestedUNet --deep_supervision true --optimizer SGD --scale -1 --weight_loss true  --loss WeightBCELoss --data_name HeLa --epochs 60
python3 train_mic.py --experiment MIC00029 --batch-size 1 --arch NestedUNet --deep_supervision true --optimizer SGD --scale -1 --weight_loss true  --loss WeightBCELoss --data_name HeLa --epochs 60
python3 train_mic.py --experiment MIC00030 --batch-size 1 --arch NestedUNet --deep_supervision true --optimizer SGD --scale -1 --weight_loss true  --loss WeightBCELoss --data_name HeLa --epochs 60
python3 train_mic.py --experiment MIC00031 --batch-size 1 --arch NestedUNet --deep_supervision true --optimizer SGD --scale -1 --weight_loss true  --loss WeightBCELoss --data_name HeLa --epochs 60
python3 train_mic.py --experiment MIC00032 --batch-size 1 --arch NestedUNet --deep_supervision true --optimizer SGD --scale -1 --weight_loss true  --loss WeightBCELoss --data_name HeLa --epochs 60
python3 train_mic.py --experiment MIC00033 --batch-size 1 --arch NestedUNet --deep_supervision true --optimizer SGD --scale -1 --weight_loss true  --loss WeightBCELoss --data_name HeLa --epochs 60
python3 train_mic.py --experiment MIC00034 --batch-size 1 --arch NestedUNet --deep_supervision true --optimizer SGD --scale -1 --weight_loss true  --loss WeightBCELoss --data_name HeLa --epochs 60
python3 train_mic.py --experiment MIC00035 --batch-size 1 --arch NestedUNet --deep_supervision true --optimizer SGD --scale -1 --weight_loss true  --loss WeightBCELoss --data_name HeLa --epochs 60

#for UNet  has no deep_supervision implment
python3 train_mic.py --experiment MIC00036 --batch-size 1 --arch UNet --deep_supervision false --optimizer SGD --scale -1 --weight_loss false  --loss BCEWithLogitsLoss --data_name HeLa --epochs 60
python3 train_mic.py --experiment MIC00037 --batch-size 1 --arch UNet --deep_supervision false --optimizer SGD --scale -1 --weight_loss true  --loss WeightBCELoss --data_name HeLa --epochs 60
python3 train_mic.py --experiment MIC00038 --batch-size 1 --arch UNet --deep_supervision false --optimizer SGD --scale -1 --weight_loss true  --loss WeightBCELossNormal --data_name HeLa --epochs 60



1. focus on methods with default value
python3 train_dsb.py --experiment BASIC0001 --batch-size 10 --arch NestedUNet --deep_supervision false --optimizer Adam  --learning-rate 3e-4 --epochs 50 --weight_loss false
python3 train_dsb.py --experiment BASIC0002 --batch-size 10 --arch NestedUNet --deep_supervision true --optimizer Adam  --learning-rate 3e-4 --epochs 50 --weight_loss false
python3 train_dsb.py --experiment BASIC0003 --batch-size 10 --arch UNet --deep_supervision false --optimizer Adam  --learning-rate 1e-2 --momentum 0.99 --epochs 50 --weight_loss false

python3 train_mic.py --experiment BASIC0004 --batch-size 1 --arch NestedUNet --deep_supervision false --optimizer Adam --scale -1 --weight_loss false  --loss BCEWithLogitsLoss --data_name U373 --epochs 50 --learning-rate 3e-4
python3 train_mic.py --experiment BASIC0005 --batch-size 1 --arch NestedUNet --deep_supervision true --optimizer Adam --scale -1 --weight_loss false  --loss BCEWithLogitsLoss --data_name U373 --epochs 50 --learning-rate 3e-4
python3 train_mic.py --experiment BASIC0006 --batch-size 1 --arch UNet --deep_supervision false --optimizer SGD --scale -1 --weight_loss true  --loss WeightBCELoss --data_name U373 --epochs 50 --learning-rate 1e-2  --momentum 0.99

python3 train_mic.py --experiment BASIC0007 --batch-size 1 --arch NestedUNet --deep_supervision false --optimizer Adam --scale -1 --weight_loss false  --loss BCEWithLogitsLoss --data_name HeLa --epochs 50 --learning-rate 3e-4
python3 train_mic.py --experiment BASIC0008 --batch-size 1 --arch NestedUNet --deep_supervision true --optimizer Adam --scale -1 --weight_loss false  --loss BCEWithLogitsLoss --data_name HeLa --epochs 50 --learning-rate 3e-4
python3 train_mic.py --experiment BASIC0009 --batch-size 1 --arch UNet --deep_supervision false --optimizer SGD --scale -1 --weight_loss true  --loss WeightBCELoss --data_name HeLa --epochs 50 --learning-rate 1e-2  --momentum 0.99

python3 train_mic.py --experiment BASIC0010 --batch-size 1 --arch NestedUNet --deep_supervision false --optimizer Adam --scale -1 --weight_loss false  --loss BCEWithLogitsLoss --data_name ISBI --epochs 50 --learning-rate 3e-4
python3 train_mic.py --experiment BASIC0011 --batch-size 1 --arch NestedUNet --deep_supervision true --optimizer Adam --scale -1 --weight_loss false  --loss BCEWithLogitsLoss --data_name ISBI --epochs 50 --learning-rate 3e-4
python3 train_mic.py --experiment BASIC0012 --batch-size 1 --arch UNet --deep_supervision false --optimizer SGD --scale -1 --weight_loss true  --loss WeightBCELoss --data_name ISBI --epochs 50 --learning-rate 1e-2  --momentum 0.99




